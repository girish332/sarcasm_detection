{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.layers import Dense,Dropout,LSTM,Embedding,BatchNormalization,Activation\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as py\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/girish332/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/girish332/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p2=pd.read_json('Sarcasm_Headlines_Dataset.json',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.huffingtonpost.com/entry/obama-veterans-day_us_564372e9e4b08cda3486f09b'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2[p2['is_sarcastic']==0]\n",
    "p2.iloc[26,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2.drop('article_link',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2['headline']=p2['headline'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p2['is_sarcastic'].hist()\n",
    "py.xlabel('Ground Truth')\n",
    "py.ylabel('Frequency')\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,x_test,Y_train,y_test=train_test_split(pd.DataFrame(p2['headline']),pd.DataFrame(p2['is_sarcastic']),test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21367/21367 [00:02<00:00, 7740.88it/s]\n",
      "100%|██████████| 5342/5342 [00:00<00:00, 7377.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21367\n",
      "5342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_sentences(df):\n",
    "    clean = []\n",
    "    \n",
    "    for sent in tqdm(df['headline']):\n",
    "\n",
    "        #remove non-alphabetic characters\n",
    "        cleaned_text = re.sub(\"[^a-zA-Z]\",\" \", sent)\n",
    "    \n",
    "        #tokenize the sentences\n",
    "        words = word_tokenize(cleaned_text.lower())\n",
    "    \n",
    "        #lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "        clean.append(lemma_words)\n",
    "\n",
    "    return(clean)\n",
    "train=X_train\n",
    "test=x_test\n",
    "\n",
    "#cleaned reviews for both train and test set retrieved\n",
    "train_sentences = clean_sentences(train)\n",
    "test_sentences = clean_sentences(test)\n",
    "\n",
    "print(len(train_sentences))\n",
    "print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=Y_train.is_sarcastic.values\n",
    "y_target=to_categorical(target)\n",
    "num_classes=y_target.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val=train_test_split(train_sentences,Y_train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17093/17093 [00:00<00:00, 599647.36it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_words = set()\n",
    "len_max = 0\n",
    "\n",
    "for sent in tqdm(x_train):\n",
    "    \n",
    "    unique_words.update(sent)\n",
    "    \n",
    "    if(len_max<len(sent)):\n",
    "        len_max = len(sent)\n",
    "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_val = tokenizer.texts_to_sequences(x_val)\n",
    "x_test = tokenizer.texts_to_sequences(test_sentences)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=len_max)\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=len_max)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=len_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girish332/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/girish332/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/girish332/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(x_train)\n",
    "y_pred1=rf.predict(x_val)\n",
    "y_pred2=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Logistic Regression --------------\n",
      "\n",
      "Training accuracy = 0.5879014801380682 \n",
      "Validation accuracy= 0.582826392138512 \n",
      "Testing Accuracy= 0.5829277424185698\n"
     ]
    }
   ],
   "source": [
    "print('--------------- Logistic Regression --------------\\n')\n",
    "print('Training accuracy = {s2} \\nValidation accuracy= {s1} \\nTesting Accuracy= {s3}'.format(s1=accuracy_score(y_val,y_pred1),s2=accuracy_score(y_train,y_pred),s3=accuracy_score(y_test,y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes using MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girish332/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(x_train)\n",
    "y_pred1=rf.predict(x_val)\n",
    "y_pred2=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Naive Bayes --------------\n",
      "\n",
      "Training accuracy = 0.5316796349382789 \n",
      "Validation accuracy= 0.5229293401965373 \n",
      "Testing Accuracy= 0.5196555597154624\n"
     ]
    }
   ],
   "source": [
    "print('--------------- Naive Bayes --------------\\n')\n",
    "print('Training accuracy = {s2} \\nValidation accuracy= {s1} \\nTesting Accuracy= {s3}'.format(s1=accuracy_score(y_val,y_pred1),s2=accuracy_score(y_train,y_pred),s3=accuracy_score(y_test,y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girish332/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/girish332/.local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(x_train)\n",
    "y_pred1=rf.predict(x_val)\n",
    "y_pred2=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Random Forest Classifier --------------\n",
      "\n",
      "Training accuracy = 0.9867782133036915 \n",
      "Validation accuracy= 0.6202620496022462 \n",
      "Testing Accuracy= 0.6276675402470985\n"
     ]
    }
   ],
   "source": [
    "print('--------------- Random Forest Classifier --------------\\n')\n",
    "print('Training accuracy = {s2} \\nValidation accuracy= {s1} \\nTesting Accuracy= {s3}'.format(s1=accuracy_score(y_val,y_pred1),s2=accuracy_score(y_train,y_pred),s3=accuracy_score(y_test,y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=SVC(C=1e+8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girish332/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/girish332/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100000000.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(x_train)\n",
    "y_pred1=rf.predict(x_val)\n",
    "y_pred2=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- SVM --------------\n",
      "\n",
      "Training accuracy = 1.0 \n",
      "Validation accuracy= 0.5708937763219466 \n",
      "Testing Accuracy= 0.5690752527143392\n"
     ]
    }
   ],
   "source": [
    "print('--------------- SVM --------------\\n')\n",
    "print('Training accuracy = {s2} \\nValidation accuracy= {s1} \\nTesting Accuracy= {s3}'.format(s1=accuracy_score(y_val,y_pred1),s2=accuracy_score(y_train,y_pred),s3=accuracy_score(y_test,y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val=train_test_split(train_sentences,y_target,test_size=0.2)  #y_target for LSTM,Y_train for traditional models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17093/17093 [00:00<00:00, 557850.23it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_words = set()\n",
    "len_max = 0\n",
    "for sent in tqdm(x_train):\n",
    "    unique_words.update(sent)\n",
    "    if(len_max<len(sent)):\n",
    "        len_max = len(sent)\n",
    "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_val = tokenizer.texts_to_sequences(x_val)\n",
    "x_test = tokenizer.texts_to_sequences(test_sentences)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=len_max)\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=len_max)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0921 16:37:20.502113 140359559481152 deprecation.py:506] From /home/girish332/.local/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0921 16:37:20.516371 140359559481152 deprecation.py:506] From /home/girish332/.local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "ml = Sequential()\n",
    "ml.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
    "ml.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
    "ml.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "ml.add(Dense(50,activation='relu'))\n",
    "ml.add(Dropout(0.5))\n",
    "ml.add(Dense(50))\n",
    "ml.add(BatchNormalization())\n",
    "ml.add(Activation('relu'))\n",
    "ml.add(Dense(50,activation='relu'))\n",
    "ml.add(Dense(50))\n",
    "ml.add(Dense(num_classes,activation='softmax'))\n",
    "ml.compile(optimizer=RMSprop(lr=0.01),metrics=['accuracy'],loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ml.fit(x_train,y_train,validation_data=[x_val,y_val],epochs=2,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=ml.predict_classes(x_val)\n",
    "y_pred1=ml.predict_classes(x_train)\n",
    "y_pred2=ml.predict_classes(x_test)\n",
    "y_val1=np.argmax(y_val,axis=1)\n",
    "y_train1=np.argmax(y_train,axis=1)\n",
    "str1='Training accuracy = {s2} \\nValidation accuracy= {s1} \\nTesting Accuracy= {s3}'.format(s1=accuracy_score(y_val1,y_pred),s2=accuracy_score(y_train1,y_pred1),s3=accuracy_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- LSTM --------------\n",
      "\n",
      "Training accuracy = 0.5446089042298017 \n",
      "Validation accuracy= 0.5383715489003276 \n",
      "Testing Accuracy= 0.5469861475102957\n"
     ]
    }
   ],
   "source": [
    "print('--------------- LSTM --------------\\n')\n",
    "print(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_4_input to have shape (37,) but got array with shape (38,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3bc7c597f3bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_val1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \"\"\"\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;31m# generate symbolic tensors).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     x, _, _ = self._standardize_user_data(\n\u001b[0;32m-> 1060\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    383\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    386\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_4_input to have shape (37,) but got array with shape (38,)"
     ]
    }
   ],
   "source": [
    "y_pred=ml.predict_classes(x_val)\n",
    "y_pred1=m1.predict_classes(x_train)\n",
    "y_pred2=m1.predict_classes(x_test)\n",
    "y_val1=np.argmax(y_val,axis=1)\n",
    "y_train1=np.argmax(y_train,axis=1)\n",
    "str1='Training accuracy = {s2} \\nValidation accuracy= {s1} \\nTesting Accuracy= {s3}'.format(s1=accuracy_score(y_val1,y_pred),s2=accuracy_score(y_train1,y_pred1),s3=accuracy_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      2986\n",
      "           1       0.85      0.80      0.82      2356\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5342\n",
      "   macro avg       0.85      0.84      0.85      5342\n",
      "weighted avg       0.85      0.85      0.85      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2662  324]\n",
      " [ 480 1876]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(sent):\n",
    "    sent1=clean_sentences(sent)\n",
    "    senti=tokenizer.texts_to_sequences(sent1)\n",
    "    senti=sequence.pad_sequences(senti,maxlen=len_max)\n",
    "    return senti\n",
    "def predict_value(senten):\n",
    "    di={'headline':senten}\n",
    "    pd1=pd.DataFrame(di,index=[0])\n",
    "    #print(pd1.head())\n",
    "    s=ml.predict_proba(process(pd1))\n",
    "    print('The model is {s1}% confident that the sentence is sarcastic'.format(s1=(s[0][1]*100).round(decimals=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 912.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is 81.53% confident that the sentence is sarcastic\n"
     ]
    }
   ],
   "source": [
    "s=predict_value('Cancer cures smoking')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
